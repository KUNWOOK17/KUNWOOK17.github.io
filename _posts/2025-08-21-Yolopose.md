---
title: "AI 기반 협동 로봇 작업 보조 시스템: YOLO 객체 탐지 및 인간-로봇 상호작용(HRI) 지능을 활용한 비전 기반 접근법"
excerpt: "YOLO 기반 인공지능 비전 기술을 활용한 협동 로봇 작업 보조 시스템"
date: 2025-08-21
layout: post
categories: [Precision Control, ROS2, Doosan M0609, STT, TTS]
tags: [YOLOv8, Doosan M0609, STT, TTS]
toc: true
toc_sticky: true
---

> *"기계가 보고 이해하기 시작할 때, 협업은 비로소 직관이 된다."*

---
<div class="youtube-wrapper">
  <iframe
    src="https://www.youtube.com/embed/Fas-aIrPaJc"
    title="Liquid Injection Control Demo"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>


---
## 초록 (Abstract)

본 프로젝트는 협동 로봇인 **두산 M0609**와 Realsense, Yolo 를 활용하여, **가정용 실시간 반응 로봇** 개발을 다룹니다. 주어진 **두산 M0609** 모델과 Realsense의 기능적 활용을 최대화하기 위해 **AI 기반 협동 로봇 작업 보조 시스템**을 구현했습니다.

---

### 1. 서론 및 문제 정의 (Introduction & Problem Formulation)

![Robotics market comparison](/assets/images/Yolopose/Robotics_market_comparison.png)  
*그림 1. 로봇 산업 주요 세부 시장의 연도별 시장 규모 성장 추세 (USD 기준)*

위 공개 수치를 바탕으로, 가정 내 로봇팔은 아직 “전체 가정용 로봇 시장 속 작은 하위영역”이지만
① 가정용 로봇 시장 자체의 고성장, ② 로봇팔 가격 하락과 소형화, ③ AI 기반 조작(비전·LLM)의 성능 향상, ④ 고령화로 인한 재가 돌봄/보조 조작 수요 증가에 힘입어 중기적으로 빠르게 확대될 가능성이 크다

---

### 2. 시스템 아키텍처 및 설계 (System Architecture & Design)
![node Overview](/assets/images/Yolopose/node_system.png)  
*그림 2: Realsense와 M0609 협업 및 통신 구조를 포함한 전체 시스템 아키텍처*

![System Overview](/assets/images/Yolopose/system_overview.png)  
*그림 3: 시스템의 전체 흐름 및 예시*

### 2.1 기술 스택 개요 (Technical Stack Overview)

| 구성 요소 | 구현 기술 | 선택 근거 |
|----------|----------|-----------|
| **객체 탐지** | YOLOv11 | 속도와 정확도 간 최적의 균형 |
| **자세 추정** | YOLOv11-pose | 실시간 키포인트 기반 자세 추정으로 동작/방향을 안정적으로 파악 |
| **좌표 변환** | TF2 프레임워크 | 카메라–로봇 간 좌표계를 실시간으로 변환하는 ROS2 네이티브 프레임워크 |
| **기술 구현** | 비전–로봇 통합 파이프라인 | 인식·좌표 변환·로봇 제어를 하나의 실시간 처리 흐름으로 통합 |
| **플랫폼** | Ubuntu 22.04 + ROS2 | 안정성 및 활발한 커뮤니티 지원 |


---

### 3. 객체 탐지 시스템

### 3.1 데이터셋 준비 및 모델 선정

**데이터셋 세부 사양:**
- **총 샘플 수:** 약 4,000개 (훈련: 2,800개, 검증: 800개, 테스트: 400개)
- **클래스:** phone, book, wallet, laptop, hand, vitamin, airpods, pencilcase
- **형식:** YOLO 어노테이션 형식
- **해상도:** 640×640 픽셀 (학습 시 리사이즈)
- **데이터 증강:** 회전, 스케일 변화, 밝기 변화를 포함한 기본적인 이미지 증강 적용


### 3.2 모델 성능 분석

추론 시간 분포를 이용한 YOLO 모델 간 비교 분석 결과는 다음과 같습니다:

![System Overview](/assets/images/Yolopose/Yolo_comparechart.png)  
*그림 4: Yolo 모델 간 비교 분석 결과*


| 모델           | 추론 시간 (ms/img) | COCO mAP@0.5:0.95 | 특징                     |
| :----------- | :------------: | :---------------: | :--------------------- |
| YOLOv5n      |      ~4.0      |       ~0.38       | 경량 모델, 비교 기준선          |
| YOLOv8n      |      ~3.5      |       ~0.39       | v5 대비 정확도·속도 개선        |
| YOLOv9n      |      ~3.0      |       ~0.38       | 연산 효율 중심 설계            |
| **YOLOv11n** |    **~2.0**    |     **~0.40**     | **최소 지연 시간 대비 최고 정확도** |
| YOLOv11s     |      ~2.5      |       ~0.47       | 소형 모델 중 높은 정확도         |
| YOLOv11m     |      ~5.0      |       ~0.52       | 정확도–속도 균형              |
| YOLOv11x     |      ~12.0     |       ~0.55       | 최고 성능, 높은 연산 비용        |


**선정 근거:** YOLOv11n은 추론시간이 짧아 빠른 응답속도와 최고 수준 정확도를 보여줍니다.

---

### 4. Yolov11n

### 4.1 Pose estimation
## 지원되는 작업 및 모드

YOLO11은 이전 Ultralytics YOLO 릴리스에서 구축한 다목적 모델 범위를 기반으로, 다양한 컴퓨터 비전 작업에 대해 향상된 지원을 제공한다.

| 모델 | 파일 이름 | 작업 | 추론 | 검증 | 훈련 | 내보내기 |
| :--- | :--- | :--- | :---: | :---: | :---: | :---: |
| YOLO11 | yolov11n.pt<br>yolov11s.pt<br>yolov11m.pt<br>yolov11l.pt<br>yolov11x.pt | 객체 탐지 | ✅ | ✅ | ✅ | ✅ |
| YOLO11-seg | yolov11n-seg.pt<br>yolov11s-seg.pt<br>yolov11m-seg.pt<br>yolov11l-seg.pt<br>yolov11x-seg.pt | 인스턴스 분할 | ✅ | ✅ | ✅ | ✅ |
| YOLO11-pose | yolov11n-pose.pt<br>yolov11s-pose.pt<br>yolov11m-pose.pt<br>yolov11l-pose.pt<br>yolov11x-pose.pt | 포즈/키포인트 | ✅ | ✅ | ✅ | ✅ |
| YOLO11-obb | yolov11n-obb.pt<br>yolov11s-obb.pt<br>yolov11m-obb.pt<br>yolov11l-obb.pt<br>yolov11x-obb.pt | 방향 감지 (OBB) | ✅ | ✅ | ✅ | ✅ |
| YOLO11-cls | yolov11n-cls.pt<br>yolov11s-cls.pt<br>yolov11m-cls.pt<br>yolov11l-cls.pt<br>yolov11x-cls.pt | 분류 | ✅ | ✅ | ✅ | ✅ |

이 표는 YOLO11 모델의 다양한 변형에 대한 개요를 제공하며, 특정 작업에서의 적용 가능성과 추론, 검증, 훈련 및 내보내기와 같은 작동 모드와의 호환성을 보여준다. 이러한 유연성 덕분에 YOLO11은 실시간 감지부터 복잡한 분할 작업에 이르기까지 컴퓨터 비전 분야의 광범위한 응용에 적합하다.

**YOLOv11 주요 특징 및 장점**

- **향상된 특징 추출**  
  YOLOv11은 개선된 백본(backbone) 및 넥(neck) 아키텍처를 사용하여 보다 정확한 객체 탐지와 복잡한 작업 수행을 위한 특징 추출 성능을 향상시킨다.

- **효율성 및 속도에 최적화된 설계**  
  개선된 아키텍처 설계와 최적화된 학습 파이프라인을 도입하여 더 빠른 처리 속도를 제공하며, 정확도와 성능 간의 최적 균형을 유지한다.

- **더 적은 매개변수로 더 높은 정확도**  
  모델 설계의 발전을 통해 YOLOv11m은 YOLOv8m 대비 약 22% 적은 매개변수를 사용하면서도 COCO 데이터셋에서 더 높은 mean Average Precision(mAP)을 달성하여 계산 효율성을 향상시켰다.

- **다양한 환경에 대한 높은 적응성**  
  YOLOv11은 엣지 디바이스, 클라우드 플랫폼, NVIDIA GPU 기반 시스템 등 다양한 환경에 원활하게 배포될 수 있도록 설계되어 높은 유연성을 제공한다.

- **광범위한 비전 작업 지원**  
  객체 탐지(Object Detection), 인스턴스 분할(Instance Segmentation), 이미지 분류(Image Classification), 포즈 추정(Pose Estimation), OBB(Oriented Bounding Box Detection) 등 다양한 컴퓨터 비전 작업을 단일 프레임워크에서 지원한다.

### 4.2 Pose estimation

## 성능 (Pose · COCO)

아래 표는 COCO 데이터셋에서 학습된 YOLOv11 Pose 모델들의 성능을 비교한 결과이다.  
모든 모델은 입력 해상도 640×640 기준으로 평가되었으며, 정확도(mAP)와 추론 속도, 모델 복잡도를 함께 제시한다.

| 모델 | 입력 크기 (픽셀) | mAP<sub>pose</sub> 50–95 | mAP<sub>pose</sub> 50 | 속도 CPU ONNX (ms) | 속도 T4 TensorRT10 (ms) | 파라미터 (M) | FLOPs (B) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| YOLOv11n-pose | 640 | 50.0 | 81.0 | 52.4 ± 0.5 | 1.7 ± 0.0 | 2.9 | 7.4 |
| YOLOv11s-pose | 640 | 58.9 | 86.3 | 90.5 ± 0.6 | 2.6 ± 0.0 | 9.9 | 23.1 |
| YOLOv11m-pose | 640 | 64.9 | 89.4 | 187.3 ± 0.8 | 4.9 ± 0.1 | 20.9 | 71.4 |
| YOLOv11l-pose | 640 | 66.1 | 89.9 | 247.7 ± 1.1 | 6.4 ± 0.1 | 26.1 | 90.3 |
| YOLOv11x-pose | 640 | 69.5 | 91.1 | 488.0 ± 13.9 | 12.1 ± 0.2 | 58.8 | 202.8 |


---

## 5. STT & TTS

## STT

STT는 음성 입력을 Mel Spectrogram으로 변환한 후, , Transformer 기반 인코더-디코더 구조를 통해 문장 단위 텍스트를 예측한다.
본 프로젝트에서 사용한 Whisper 모델은 다국어·잡음 환경에서도 강건하며, 음성 전사뿐 아니라 번역·언어 식별까지 지원한다.

## Mel Spectrogram

**신호 (Signals)**

신호란 시간에 따라 어떤 물리량이 변화하는 현상을 의미한다.  
오디오 신호의 경우, 시간에 따라 변화하는 물리량은 **공기 압력(air pressure)**이다.

이러한 정보를 디지털 형태로 기록하기 위해, 우리는 시간에 따른 공기 압력을 **샘플링(sampling)**하여 측정한다.  
샘플링 속도는 응용 분야에 따라 달라질 수 있으나, 가장 일반적으로 사용되는 값은 **44.1kHz**, 즉 **초당 44,100개의 샘플**이다.

이 과정을 통해 얻어진 결과는 해당 신호의 **파형(waveform)**이며,  
이 파형은 컴퓨터 소프트웨어를 통해 시각화되거나 해석, 수정 및 분석될 수 있다.

이제 우리는 오디오 신호를 디지털 형태로 표현했으며, 이를 자유롭게 다룰 수 있게 되었다.  
신호 처리(signal processing) 분야에 오신 것을 환영한다!

하지만 한 가지 의문이 생길 수 있다.  
이 복잡해 보이는 파형에서 **어떻게 유용한 정보를 추출할 수 있을까?**  
시간 영역에서의 신호는 종종 뒤섞인 형태로 보이며, 직관적으로 해석하기 어렵다.  
바로 이 지점에서 우리의 친구 **푸리에(Fourier)**가 등장한다.

**푸리에 변환 (Fourier Transform)**

오디오 신호는 여러 개의 **단일 주파수(sound wave)** 성분이 결합된 형태로 구성되어 있다.  
시간에 따라 신호를 샘플링할 때, 우리는 이 성분들이 합쳐진 결과인 **진폭(amplitude)**만을 관측하게 된다.

**푸리에 변환(Fourier Transform)**은 이러한 신호를 개별 주파수 성분과 각 주파수의 진폭으로 분해할 수 있도록 해주는 수학적 변환이다.  
즉, 신호를 **시간 영역(time domain)**에서 **주파수 영역(frequency domain)**으로 변환하는 역할을 한다.

이 변환의 결과는 **스펙트럼(spectrum)**이라 불리며,  
신호에 어떤 주파수 성분이 포함되어 있는지를 명확하게 보여준다.

```python
import librosa
import librosa.display
import matplotlib.pyplot as plt
y, sr = librosa.load('./example_data/88b3a759.wav')
plt.plot(y);
plt.title('Signal');
plt.xlabel('Time (samples)');
plt.ylabel('Amplitude');
```
![System Overview](/assets/images/Yolopose/Mel_Spectrogram_1.png)  
*그림 5: 시간 영역에서의 오디오 신호 파형*


```python
import numpy as np
n_fft = 2048
ft = np.abs(librosa.stft(y[:n_fft], hop_length = n_fft+1))
plt.plot(ft);
plt.title('Spectrum');
plt.xlabel('Frequency Bin');
plt.ylabel('Amplitude');
```
![System Overview](/assets/images/Yolopose/Mel_Spectrogram_2.png)  
*그림 6: 푸리에 변환을 통해 얻은 오디오 신호의 주파수 스펙트럼*



```python
spec = np.abs(librosa.stft(y, hop_length=512))
spec = librosa.amplitude_to_db(spec, ref=np.max)
librosa.display.specshow(spec, sr=sr, x_axis='time', y_axis='log');
plt.colorbar(format='%+2.0f dB');
plt.title('Spectrogram');
```
![System Overview](/assets/images/Yolopose/Mel_Spectrogram_3.png)  
*그림 7: 단시간 푸리에 변환(STFT)을 이용해 계산한 오디오 신호의 스펙트로그램*



```python
spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)
mel_spect = librosa.power_to_db(spect, ref=np.max)
librosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');
plt.title('Mel Spectrogram');
plt.colorbar(format='%+2.0f dB');
```
![System Overview](/assets/images/Yolopose/Mel_Spectrogram_4.png)  
*그림 8: 멜 필터 뱅크를 적용하여 계산한 오디오 신호의 멜 스펙트로그램*





---

## 6. Blob Detection

---

## 7. 

---

## 8. 

---

## 9. 문제점 및 해결 방안 (Challenges & Solutions)

---

## 10. 성능 평가 및 결과

---

## 11. 향후 연구 및 발전 방향

---
## 12. 결론 (Conclusion)

---

## Acknowledgments

---

## References

1. [Min](https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53)

---

## Appendix A: Technical Specifications

---

## Image Requirements Summary